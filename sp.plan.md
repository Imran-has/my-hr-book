Title: Physical AI & Humanoid Robotics  
Subtitle: From Digital Intelligence to Embodied Machines

-----------------------------------------------------
üìò PART I ‚Äî FOUNDATIONS OF PHYSICAL AI
-----------------------------------------------------

Chapter 1 ‚Äî Introduction to Physical AI  
- What is Physical AI?  
- Embodied Intelligence vs. Digital Intelligence  
- Why humanoid robots?  
- Physical laws, perception, and motor grounding  
- Overview of the course architecture: ROS 2, Gazebo, Unity, Isaac, VLA, RAG  

Chapter 2 ‚Äî Humanoid Robotics Landscape  
- Tesla Optimus, Figure 01, Atlas, Unitree H1/G1  
- Current industry challenges  
- Embodied foundation models  
- Sim-to-Real gap  

-----------------------------------------------------
üìò PART II ‚Äî MODULE 1: THE ROBOTIC NERVOUS SYSTEM (ROS 2)
-----------------------------------------------------

Chapter 3 ‚Äî ROS 2 Architecture  
- Nodes, topics, services, actions  
- DDS communication  
- ROS 2 workspace setup  
- Python rclpy vs. C++ overview  

Chapter 4 ‚Äî Building ROS 2 Packages (Python)  
- Colcon workspace  
- ROS 2 launch files  
- Parameter servers  
- Lifecycle nodes  
- Logging & debugging robotic controllers  

Chapter 5 ‚Äî URDF & Humanoid Robot Description  
- URDF structure  
- Joints, links, inertia  
- Loading URDF into RViz2  
- Creating a humanoid model skeleton  

-----------------------------------------------------
üìò PART III ‚Äî MODULE 2: THE DIGITAL TWIN (GAZEBO & UNITY)
-----------------------------------------------------

Chapter 6 ‚Äî Gazebo Simulation Fundamentals  
- SDF vs. URDF  
- Physics simulation (ODE, Bullet, DART)  
- Sensors: LiDAR, Depth Camera, IMU  
- Collision, friction, dynamics tuning  

Chapter 7 ‚Äî Unity Robotics Integration  
- Unity environment setup  
- Human-in-the-loop simulation  
- High-fidelity rendering for perception  
- Humanoid interaction scenes  

Chapter 8 ‚Äî Building the Digital Twin  
- Synchronizing ROS 2 with Gazebo  
- Importing humanoid models  
- Testing locomotion in simulation  
- Sensor validation pipeline  

-----------------------------------------------------
üìò PART IV ‚Äî MODULE 3: THE AI-ROBOT BRAIN (NVIDIA ISAAC)
-----------------------------------------------------

Chapter 9 ‚Äî NVIDIA Isaac Sim  
- USD scenes  
- RTX simulation  
- Domain randomization  
- Synthetic data pipelines  

Chapter 10 ‚Äî Isaac ROS & Perception  
- VSLAM (Visual SLAM)  
- Stereo + Depth processing  
- Visual Odometry  
- Isaac ROS GEMs  

Chapter 11 ‚Äî Navigation & Bipedal Planning  
- Nav2 stack for humanoid movement  
- Footstep planning  
- Obstacle avoidance  
- Reinforcement learning control loops  

-----------------------------------------------------
üìò PART V ‚Äî MODULE 4: VISION-LANGUAGE-ACTION (VLA)
-----------------------------------------------------

Chapter 12 ‚Äî Voice-to-Action Systems  
- OpenAI Whisper for command recognition  
- Turning speech ‚Üí semantic intentions  
- Safety & validation  

Chapter 13 ‚Äî Cognitive Planning with LLMs  
- Natural language ‚Üí ROS 2 tasks  
- Symbol grounding  
- Long-horizon robotic behavior  
- Examples: ‚ÄúClean the room‚Äù, ‚ÄúPick the bottle‚Äù  

Chapter 14 ‚Äî Embodied VLA Models  
- Vision + Language + Robotics fusion  
- Using LLMs inside robotic control loops  
- Constraint-based planning  
- Integration with perception stack  

-----------------------------------------------------
üìò PART VI ‚Äî RAG-POWERED BOOK CHATBOT (Major Project)
-----------------------------------------------------

Chapter 15 ‚Äî Building the RAG Chatbot Backend  
- FastAPI  
- OpenAI Agents/ChatKit SDK  
- Embedding generation  
- Qdrant Cloud vector store  
- Neon Postgres metadata store  

Chapter 16 ‚Äî Docusaurus Chatbot Integration  
- Chatbot frontend widget  
- Text selection ‚Üí context injection  
- Grounded Q&A system  
- Deployment to GitHub Pages  

-----------------------------------------------------
üìò PART VII ‚Äî HUMANOID ROBOT ENGINEERING
-----------------------------------------------------

Chapter 17 ‚Äî Humanoid Kinematics & Dynamics  
- Forward/Inverse Kinematics  
- Bipedal balance  
- ZMP (Zero Moment Point)  
- Inertia, torque, COM management  

Chapter 18 ‚Äî Manipulation & Dexterous Hands  
- Grasp types  
- End-effector planning  
- Force control  
- Visual servo control  

Chapter 19 ‚Äî Natural Human‚ÄìRobot Interaction  
- Speech  
- Gesture  
- Emotion-aware responses  
- Safety layers for humans  

-----------------------------------------------------
üìò PART VIII ‚Äî CAPSTONE PROJECT (THE AUTONOMOUS HUMANOID)
-----------------------------------------------------

Chapter 20 ‚Äî The Final System  
- Voice command ‚Üí reasoning ‚Üí motion  
- Navigation with obstacles  
- Object identification  
- Manipulation & placement  
- VLA + ROS 2 + Isaac + Gazebo pipeline  

Chapter 21 ‚Äî Sim-to-Real Deployment  
- Jetson Orin deployment  
- RealSense & IMU calibration  
- Connecting sensors to locomotion  
- Minimizing domain gap  

-----------------------------------------------------
üìò PART IX ‚Äî APPENDICES
-----------------------------------------------------

Appendix A ‚Äî Hardware Requirements  
Appendix B ‚Äî Cloud vs. On-premise robotics lab  
Appendix C ‚Äî Jetson Edge Kit Setup  
Appendix D ‚Äî Docusaurus + GitHub Pages deployment  
Appendix E ‚Äî ROS 2 cheat sheets  
Appendix F ‚Äî Safety protocols for humanoids  
